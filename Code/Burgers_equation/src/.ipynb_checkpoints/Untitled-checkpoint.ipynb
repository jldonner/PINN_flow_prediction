{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a9a30c3-4abd-490d-92e6-45c9727b37d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~ Adam optimization ~~\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\rob\\Desktop\\Uni2\\Proejkt\\Robin\\Code\\Burger_setup_vikas\\src\\../optimizer\\NeuralNet_optimizer.py\", line 222, in Adam_train_step  *\n        total_loss, mass_loss, progress_loss, mom_loss1, mom_loss2, b_loss, n_loss, i_loss, d_loss, w_loss = self.loss()\n    File \"C:\\Users\\rob\\Desktop\\Uni2\\Proejkt\\Robin\\Code\\Burger_setup_vikas\\src\\PDE.py\", line 80, in loss  *\n        progress_loss = self.net_progress_loss()\n    File \"C:\\Users\\rob\\Desktop\\Uni2\\Proejkt\\Robin\\Code\\Burger_setup_vikas\\src\\PDE.py\", line 137, in net_progress_loss  *\n        u1 = self.model(x_colloc)\n    File \"C:\\Users\\rob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\rob\\AppData\\Local\\Temp\\__autograph_generated_fileskqhntlo.py\", line 11, in tf__call\n        output = ag__.converted_call(ag__.converted_call(ag__.ld(super), (ag__.ld(neural_net), ag__.ld(self)), None, fscope).call, (ag__.ld(inputs),), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'neural_net_2' (type neural_net).\n    \n    in user code:\n    \n        File \"C:\\Users\\rob\\Desktop\\Uni2\\Proejkt\\Robin\\Code\\Burger_setup_vikas\\src\\PDE.py\", line 27, in call  *\n            output = super(neural_net, self).call(inputs)\n        File \"C:\\Users\\rob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\sequential.py\", line 405, in call  **\n            return super().call(inputs, training=training, mask=mask)\n        File \"C:\\Users\\rob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\functional.py\", line 512, in call\n            return self._run_internal_graph(inputs, training=training, mask=mask)\n        File \"C:\\Users\\rob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\functional.py\", line 669, in _run_internal_graph\n            outputs = node.layer(*args, **kwargs)\n        File \"C:\\Users\\rob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\rob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 280, in assert_input_compatibility\n            raise ValueError(\n    \n        ValueError: Input 0 of layer \"dense_14\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (4000, 2)\n    \n    \n    Call arguments received by layer 'neural_net_2' (type neural_net):\n      • inputs=tf.Tensor(shape=(4000, 2), dtype=float64)\n      • training=False\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 163\u001b[0m\n\u001b[0;32m    157\u001b[0m checkpoint_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Checkpoint/1D_flame_theta_as_data_loss\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# model.model.load_weights('./Checkpoint/1D_theta_mp_1000_50000_nondim_30_6_init_10_10_100.index')\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# model.model.load_weights(checkpoint_str_NN)\u001b[39;00m\n\u001b[1;32m--> 163\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43madam_iterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlbfgs_max_iterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[0;32m    165\u001b[0m \n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m#%%\u001b[39;00m\n\u001b[0;32m    168\u001b[0m model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mload_weights(checkpoint_str)\n",
      "File \u001b[1;32m~\\Desktop\\Uni2\\Proejkt\\Robin\\Code\\Burger_setup_vikas\\src\\../optimizer\\NeuralNet_optimizer.py:143\u001b[0m, in \u001b[0;36mPhysicsInformedNN.train\u001b[1;34m(self, Adam_iterations, LBFGS_max_iterations, checkpoint_str, lr_epochs, lr_list)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m#Train step\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Adam_iterations):\n\u001b[1;32m--> 143\u001b[0m     current_loss, mass_loss, progress_loss, mom_loss1, mom_loss2, b_loss, n_loss, i_loss, d_loss, w_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam_train_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m current_loss\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;241m<\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mAdam_hist): \n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file4dup6g0e.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__Adam_train_step\u001b[1;34m(self, optimizer)\u001b[0m\n\u001b[0;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m---> 11\u001b[0m     total_loss, mass_loss, progress_loss, mom_loss1, mom_loss2, b_loss, n_loss, i_loss, d_loss, w_loss \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m grads \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tape)\u001b[38;5;241m.\u001b[39mgradient, (ag__\u001b[38;5;241m.\u001b[39mld(total_loss), ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrainable_variables), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     13\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(optimizer)\u001b[38;5;241m.\u001b[39mapply_gradients, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mzip\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(grads), ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrainable_variables), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filexchaob53.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__loss\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     10\u001b[0m u_boundary \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mu_boundary\n\u001b[0;32m     11\u001b[0m u_sim \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mu_sim\n\u001b[1;32m---> 12\u001b[0m progress_loss \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet_progress_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m yS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mreduce_mean, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39msquare, (ag__\u001b[38;5;241m.\u001b[39mld(progress_loss),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     14\u001b[0m u_boundary_pred \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mnet_data_loss, (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mx_t_boundary,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filem_ol968o.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__net_progress_loss\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     10\u001b[0m nu \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mnu\n\u001b[0;32m     11\u001b[0m x_colloc \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mx_t_colloc\n\u001b[1;32m---> 12\u001b[0m u1 \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_colloc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m u \u001b[38;5;241m=\u001b[39m (ag__\u001b[38;5;241m.\u001b[39mld(u1) \u001b[38;5;241m+\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mscale_out[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m*\u001b[39m (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mscale_max[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mscale_min[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mscale_out[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mscale_min[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     14\u001b[0m du \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mgradients, (ag__\u001b[38;5;241m.\u001b[39mld(u), ag__\u001b[38;5;241m.\u001b[39mld(x_colloc)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileskqhntlo.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m      9\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     10\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m---> 11\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneural_net\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\rob\\Desktop\\Uni2\\Proejkt\\Robin\\Code\\Burger_setup_vikas\\src\\../optimizer\\NeuralNet_optimizer.py\", line 222, in Adam_train_step  *\n        total_loss, mass_loss, progress_loss, mom_loss1, mom_loss2, b_loss, n_loss, i_loss, d_loss, w_loss = self.loss()\n    File \"C:\\Users\\rob\\Desktop\\Uni2\\Proejkt\\Robin\\Code\\Burger_setup_vikas\\src\\PDE.py\", line 80, in loss  *\n        progress_loss = self.net_progress_loss()\n    File \"C:\\Users\\rob\\Desktop\\Uni2\\Proejkt\\Robin\\Code\\Burger_setup_vikas\\src\\PDE.py\", line 137, in net_progress_loss  *\n        u1 = self.model(x_colloc)\n    File \"C:\\Users\\rob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\rob\\AppData\\Local\\Temp\\__autograph_generated_fileskqhntlo.py\", line 11, in tf__call\n        output = ag__.converted_call(ag__.converted_call(ag__.ld(super), (ag__.ld(neural_net), ag__.ld(self)), None, fscope).call, (ag__.ld(inputs),), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'neural_net_2' (type neural_net).\n    \n    in user code:\n    \n        File \"C:\\Users\\rob\\Desktop\\Uni2\\Proejkt\\Robin\\Code\\Burger_setup_vikas\\src\\PDE.py\", line 27, in call  *\n            output = super(neural_net, self).call(inputs)\n        File \"C:\\Users\\rob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\sequential.py\", line 405, in call  **\n            return super().call(inputs, training=training, mask=mask)\n        File \"C:\\Users\\rob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\functional.py\", line 512, in call\n            return self._run_internal_graph(inputs, training=training, mask=mask)\n        File \"C:\\Users\\rob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\functional.py\", line 669, in _run_internal_graph\n            outputs = node.layer(*args, **kwargs)\n        File \"C:\\Users\\rob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\rob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 280, in assert_input_compatibility\n            raise ValueError(\n    \n        ValueError: Input 0 of layer \"dense_14\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (4000, 2)\n    \n    \n    Call arguments received by layer 'neural_net_2' (type neural_net):\n      • inputs=tf.Tensor(shape=(4000, 2), dtype=float64)\n      • training=False\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Feb 11 08:54:08 2023\n",
    "\n",
    "@author: vikas\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from scipy import io as sio\n",
    "# from pyDOE import lhs\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from scipy.stats import qmc\n",
    "from scipy.interpolate import griddata\n",
    "import h5py\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from scipy import interpolate\n",
    "from PDE import PINN_PDE\n",
    "from Data_NN import Data_NN\n",
    "from pyDOE import lhs\n",
    "\n",
    "#%% Constants\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#umin = np.array([umin]) \n",
    "#umax = np.array([umax]) \n",
    "\n",
    "# Read the data from reference file\n",
    "hf = h5py.File('./Data_Burgers/burgers_shock.h5','r')\n",
    "t = np.array(hf.get('/t')).T\n",
    "x = np.array(hf.get('/x')).T\n",
    "Exact = np.array(hf.get('/usol'))\n",
    "hf.close()\n",
    "nu = 0.01/np.pi\n",
    "\n",
    "X, T = np.meshgrid(x,t)\n",
    "\n",
    "X_all = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "\n",
    "Uexact_all = Exact.flatten()[:,None]              \n",
    "\n",
    "# Domain bounds\n",
    "lb = X_all.min(0)\n",
    "ub = X_all.max(0)\n",
    "\n",
    "scale_out = [2.0, 1.0]\n",
    "umin = Exact.min()\n",
    "umax = Exact.max()\n",
    "scale= [umin,umax]\n",
    "\n",
    "# First, we define the points associated with the initial condition, which is known\n",
    "# Uniformly distributed points in x-domain [-1,1] for the initial condition\n",
    "# u = -sin(pi*x)\n",
    "\n",
    "Nx_init = 50\n",
    "x_init = np.linspace(lb[0],ub[0],Nx_init)\n",
    "x_init_scaled = x_init/ub[0]\n",
    "#print(x_init)\n",
    "u_x_init = -1*np.sin(np.pi*x_init)\n",
    "u_x_init_scaled = u_x_init/umax\n",
    "#print(u_x_init)\n",
    "\n",
    "X_init = np.hstack((x_init.reshape(-1,1), np.zeros(len(x_init)).reshape(-1,1)))\n",
    "X_init_scaled = np.hstack((x_init_scaled.reshape(-1,1), np.zeros(len(x_init)).reshape(-1,1)))\n",
    "\n",
    "\n",
    "\n",
    "# Second, we define the points associated with the left and right Dirichlet boundary conditions (u=0)\n",
    "# Uniformly distributed points in t-domain [0,1] for the left BC\n",
    "\n",
    "Nt_BC = 50\n",
    "\n",
    "t_BC = np.linspace(lb[1], ub[1], Nt_BC)\n",
    "t_BC_scaled = t_BC/ub[1]\n",
    "u_train = np.zeros(len(t_BC))\n",
    "u_train_scaled = u_train/umax\n",
    "\n",
    "x_scaled_init = -np.ones(len(t_BC))\n",
    "x_scaled_init = x_scaled_init/ub[0]\n",
    "\n",
    "T_init = np.hstack((-x_scaled_init.reshape(-1,1),t_BC_scaled.reshape(-1,1) ))\n",
    "#print(T_init)\n",
    "\n",
    "# Uniformly distributed points in t-domain [0,1] for the right BC\n",
    "\n",
    "T_init1 = np.hstack((x_scaled_init.reshape(-1,1),t_BC_scaled.reshape(-1,1) ))\n",
    "#print(T_init1)\n",
    "\n",
    "\n",
    "# Stacking all the features\n",
    "\n",
    "X_train = np.vstack((X_init_scaled, T_init, T_init1))\n",
    "u_train = np.vstack((u_x_init_scaled.reshape(-1,1), u_train_scaled.reshape(-1,1), u_train_scaled.reshape(-1,1)))\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "def zufallswerte(a, b, anzahl=3):\n",
    "    \n",
    "    zufallsindices = random.sample(range(len(a)), anzahl)\n",
    "    zufallswerte_a = [a[i] for i in zufallsindices]\n",
    "    zugehoerige_werte_b = [b[i] for i in zufallsindices]\n",
    "    \n",
    "    return zufallswerte_a, zugehoerige_werte_b\n",
    "\n",
    "\n",
    "x_t_sim,u_sim = zufallswerte(X_all, Uexact_all, 500)\n",
    "x_t_sim_scaled = x_t_sim/ub\n",
    "u_sim_scaled = u_sim/umax\n",
    "\n",
    "N_colloc = 4000\n",
    "\n",
    "X_colloc_train = lb + (ub-lb)*lhs(2,N_colloc)\n",
    "X_colloc_train_scaled = X_colloc_train/ub\n",
    "\n",
    "\n",
    "layers = [1, 30, 30, 30, 30, 30, 30, 1]  \n",
    "\n",
    "scale_max = tf.convert_to_tensor(np.array([umax, 2.]))\n",
    "scale_min = tf.convert_to_tensor(np.array([umin, 0.]))\n",
    "x_t_boundary = tf.convert_to_tensor(X_train)\n",
    "u_boundary = tf.convert_to_tensor(u_train)\n",
    "x_t_colloc = tf.convert_to_tensor(X_colloc_train_scaled)\n",
    "x_t_sim = tf.convert_to_tensor(x_t_sim_scaled)\n",
    "u_sim = tf.convert_to_tensor(u_sim_scaled)\n",
    "\n",
    "model = PINN_PDE(x_t_boundary,\n",
    "                 u_boundary,\n",
    "                 x_t_colloc,\n",
    "                 x_t_sim,\n",
    "                 u_sim,\n",
    "                 ub, lb, \n",
    "                 layers,\n",
    "                 [scale_max, scale_min],\n",
    "                 scale_out,\n",
    "                 nu\n",
    "                 )\n",
    "\n",
    "#%%\n",
    "\n",
    "adam_iterations = 500  # Number of training steps \n",
    "lbfgs_max_iterations = 10000 # Max iterations for lbfgs\n",
    "\n",
    "lr_list = [1e-3,1e-4]\n",
    "lr_epochs = [200]\n",
    "\n",
    "# Loading the weights from the initialized fields for faster convergence\n",
    "# model.model.load_weights(checkpoint_str_NN)\n",
    "\n",
    "#%%\n",
    "\n",
    "#### Training\n",
    "checkpoint_str = './Checkpoint/1D_flame_theta_as_data_loss'\n",
    "   \n",
    "# model.model.load_weights('./Checkpoint/1D_theta_mp_1000_50000_nondim_30_6_init_10_10_100.index')\n",
    "# model.model.load_weights(checkpoint_str_NN)\n",
    "\n",
    "\n",
    "hist = model.train(adam_iterations, lbfgs_max_iterations, checkpoint_str, lr_epochs, lr_list)\n",
    "# \n",
    "\n",
    "#%%\n",
    "\n",
    "model.model.load_weights(checkpoint_str)\n",
    "# \n",
    "#%% Field prediction\n",
    "\n",
    "u_pred = model.predict(X_all)\n",
    "\n",
    "u_pred = np.array(u_pred)*U_IN\n",
    "\n",
    "\n",
    "\n",
    "# plt.plot(Input_all[:,0], u_pred)\n",
    "# plt.plot(Input_all[:,0], u)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "#%%  plotting functions\n",
    "\n",
    "plt.rc('font', family='serif')\n",
    "plt.rc('font', size=28)\n",
    "plt.rc('xtick', labelsize=28)\n",
    "plt.rc('ytick', labelsize=28)\n",
    "\n",
    "fig,ax = plt.subplots(1,1, figsize=(15,6))\n",
    "\n",
    "\n",
    "ax1 = ax.twinx()\n",
    "ax.plot(z,rho, label='Cantera density', linewidth=3, color='#cc0000')\n",
    "# ax.plot(X_colloc[0:10],rho_pred[0:10], 'o', linewidth=3, color='#cc0000', markersize=10, fillstyle='none')\n",
    "ax.plot(X_colloc[10:-10:10],rho_pred[10:-10:10], 'o', label='PINN density', \n",
    "        linewidth=3, color='#cc0000', markersize=10, fillstyle='none')\n",
    "# ax.plot(z[-10:],rho_pred[-10:], 'o', linewidth=3, color='#cc0000', markersize=10, fillstyle='none')\n",
    "\n",
    "ax.set_xlabel('Length')\n",
    "ax.set_ylabel(r'Density $(kg/m³)$')\n",
    "ax.legend(ncol=1,handleheight=1.4, labelspacing=0.0, handletextpad=0.2,\n",
    "                borderpad=0.2, loc='best')\n",
    "ax.set_xticks([0, 0.004, 0.008, 0.012, 0.016, 0.02])\n",
    "\n",
    "ax1.plot(z,u, label='Cantera velocity', linewidth=3, color='#0000CD')\n",
    "# ax1.plot(z[0:10],u_pred[0:10], 'd', linewidth=3, color='#228B22', markersize=10, fillstyle='none')\n",
    "ax1.plot(X_colloc[10:-10:10],u_pred[10:-10:10], 'd', label='PINN velocity', linewidth=3, color='#0000CD',\n",
    "          markersize=10, fillstyle='none')\n",
    "# ax1.plot(z[-10:],u_pred[-10:], 'd', linewidth=3, color='#228B22', markersize=10, fillstyle='none')\n",
    "\n",
    "ax1.set_ylabel(r'Velocity $(m/s)$')\n",
    "# ax1.legend(ncol=1,handleheight=1.4, labelspacing=0.0, handletextpad=0.2,\n",
    "#                 borderpad=0.2, loc='center right')\n",
    "\n",
    "# ax1.plot(z,T, label='Cantera temperature', linewidth=3, color='#228B22')\n",
    "# # ax1.plot(z[0:10],T_pred[0:10], 'd', linewidth=3, color='#228B22', markersize=10, fillstyle='none')\n",
    "# ax1.plot(X_colloc[10:-10:10],T_pred[10:-10:10], 'd', label='PINN temperature', linewidth=3, color='#228B22',\n",
    "#           markersize=10, fillstyle='none')\n",
    "# # ax1.plot(z[-10:],T_pred[-10:], 'd', linewidth=3, color='#228B22', markersize=10, fillstyle='none')\n",
    "\n",
    "# ax1.set_ylabel(r'Temperature $(K)$')\n",
    "ax1.legend(ncol=1,handleheight=1.4, labelspacing=0.0, handletextpad=0.2,\n",
    "                borderpad=0.2, loc='best')\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#%%\n",
    "######  Loss curve\n",
    "\n",
    "plt.rc('font', family='serif')\n",
    "plt.rc('font', size=18)\n",
    "plt.rc('xtick', labelsize=18)\n",
    "plt.rc('ytick', labelsize=18)\n",
    "\n",
    "\n",
    "##### Plotting losses\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,6))\n",
    "\n",
    "\n",
    "\n",
    "ax.semilogy(model.Adam_hist + model.LBFGS_hist, linewidth=3, label='Total loss',\n",
    "            color='#1f77b4')\n",
    "ax.semilogy(model.mass_cons, linewidth=3, label='Mass cons loss', \n",
    "            color='#ff7f0e')\n",
    "\n",
    "ax.semilogy(model.bound_loss, linewidth=3, label='Dirichlet loss',\n",
    "            color='#9467bd')\n",
    "ax.semilogy(model.progress_cons, linewidth=3, label='Progress loss',\n",
    "            color='#8c564b') \n",
    "ax.semilogy(model.data_loss, linewidth=3, label='Data loss',\n",
    "            color='#d62728')\n",
    "\n",
    "\n",
    "\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('MSE')\n",
    "\n",
    "ax.set_ylim([1e-6, 1e9])\n",
    "\n",
    "ax.legend(ncol=2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5973a5a5-7577-44cf-b3a6-c7a9b4a53a36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
